{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the functions below to generate a list of files for annotation "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The code in the cell below should be run within this (RightWhaleID/ImageAnnotation) folder. When run it will get a random batch of 100 images to be annotated. It will place those images in a folder (`files_for_annotation`) two levels up (alongside the `imgs` folder). After you have run this script, annotate the images using the sloth program. When you are done, use the `check_annotations` folder below to make sure that your annotations are correct. When you are happy with the json file that you created, give it a name (like `annotations_kevin_1.json`) and submit a pull request to have it included with the others."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h5>Please note that the code below assumes that you have run the script located [here](https://www.kaggle.com/c/noaa-right-whale-recognition/forums/t/16275/python-script-to-sort-images) to place the training images into folders for individual whales. The sorting script should be run at the same level as the `imgs` folder. The \n",
    "<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw\n",
    "import os\n",
    "import json\n",
    "import pandas as pd\n",
    "import random\n",
    "import shutil\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images annotated so far . . . 363\n",
      "Images still requiring annotation . . . 4181\n"
     ]
    }
   ],
   "source": [
    "# load all the json files in the annotations folder and make a list of the files that have been annotated\n",
    "files_to_search = [x for x in os.listdir(\"annotations/\") if '.json' in x]\n",
    "\n",
    "\n",
    "\n",
    "#this function takes in a json file of annotations and returns the set of images that are in it\n",
    "\n",
    "def get_annotated_images(infile):\n",
    "    annotated_images = set()\n",
    "    with open(\"annotations/\" + infile) as json_in:\n",
    "        annotations = json.load(json_in)\n",
    "        for annotation in annotations:\n",
    "            if annotation['annotations'] == []:\n",
    "                continue\n",
    "            filename = annotation['filename'][annotation['filename'].rfind('/') + 1:]\n",
    "            annotated_images.add(filename)\n",
    "            \n",
    "    return annotated_images\n",
    "\n",
    "\n",
    "# build the list of images that have already been annotated\n",
    "already_done = set()\n",
    "for json_file in files_to_search:\n",
    "    already_done = already_done.union(get_annotated_images(json_file)) \n",
    "    \n",
    "print(\"Images annotated so far . . . \" + str(len(already_done)))\n",
    "            \n",
    "            \n",
    "#get list of all images\n",
    "train_data = pd.read_csv('../Data/train.csv')\n",
    "all_images = set(train_data.Image)\n",
    "\n",
    "# make a list of all files that still require annotation\n",
    "candidate_images = all_images - already_done\n",
    "print(\"Images still requiring annotation . . . \" + str(len(candidate_images)))\n",
    "\n",
    "#select a random 100 files for annotation (do get a larger or smaller batch, change this number)\n",
    "num_files_to_annotate = 100\n",
    "images_to_annotate = random.sample(candidate_images, num_files_to_annotate)\n",
    "\n",
    "# This function takes in a list of images to be annotated and moves them to a temporary folder to be used with sloth\n",
    "def get_images_for_annotation(images):\n",
    "    if not os.path.exists('../../files_for_annotation/'):\n",
    "        os.makedirs('../../files_for_annotation/')\n",
    "    # clear out any prexisiting images \n",
    "    for jpg in os.listdir('../../files_for_annotation/'):\n",
    "        os.remove('../../files_for_annotation/' + jpg)\n",
    "    for image_name in images:\n",
    "        #look up the whale name\n",
    "        whale = train_data.whaleID[train_data.Image == image_name]\n",
    "        whale_name = whale.iloc[0]\n",
    "        #get filename and path of source - create a folder one level above the git repo\n",
    "        infile = '../../imgs/' + whale_name + '/' + image_name\n",
    "        #check for annoations folder, if it's not there, create it\n",
    "        \n",
    "                \n",
    "        outfile = '../../files_for_annotation/' + image_name\n",
    "        \n",
    "        shutil.copy(infile, outfile)\n",
    "        \n",
    "get_images_for_annotation(images_to_annotate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## use this to go over old annotations\n",
    "get_images_for_annotation(get_annotated_images('whale_05661.json'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['whale_03728.json',\n",
       " 'whale_03623.json',\n",
       " 'allan_visochek_2.json',\n",
       " 'whale_03227.json',\n",
       " 'whale_02411.json',\n",
       " 'allan_visochek_3.json',\n",
       " 'allan_visochek_1.json~',\n",
       " 'whale_05661.json',\n",
       " 'allan_visochek_1.json']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "files_to_search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function below is used to proofread annotations that you have made. It will create a group of images using your annotations to draw <span style=\"color:yellow\">yellow</span> boxes around the whale heads and <span style=\"color:red\">red</span> boxes around negative areas (that don't contain whales)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# a function to generated annotated images from a json file of whale annotations\n",
    "\n",
    "# this function assumes that there is an imgs folder two levels up and that the images in that folder have been sorted\n",
    "# with the script found here:  https://www.kaggle.com/c/noaa-right-whale-recognition/forums/t/16275/python-script-to-sort-images/91274#post91274\n",
    "\n",
    "\n",
    "#make sure you have loaded the global \n",
    "def check_annotations(jsonfile):\n",
    "    train_data = pd.read_csv('../Data/train.csv')\n",
    "    #open the json\n",
    "    with open(jsonfile, 'rb') as infile:\n",
    "        annotations = json.load(infile)\n",
    "        for annotation in annotations:\n",
    "            #if the annotation is empty, continue\n",
    "            if annotation['annotations'] == []:\n",
    "                continue\n",
    "            #open the image file and create a ImageDraw.Draw object\n",
    "            filename = annotation['filename'][annotation['filename'].rfind('/') + 1:]\n",
    "            whale = train_data.whaleID[train_data.Image == filename]\n",
    "            whale_folder = whale.iloc[0]\n",
    "            im = Image.open(\"../../imgs/\" + whale_folder + '/' + filename)\n",
    "            draw = ImageDraw.Draw(im)\n",
    "            for item in annotation['annotations']:\n",
    "                #set line color\n",
    "                if item['class'] == 'Blowholes':\n",
    "                    line_color = \"yellow\"\n",
    "                elif item['class'] == 'TipOfHead':\n",
    "                    line_color = \"red\"\n",
    "                else:\n",
    "                    continue\n",
    "                #draw the rectangle\n",
    "                x,y = item['x'], item['y']\n",
    "                for i in range(100): #this controls the width of the line drawn\n",
    "                    draw.polygon([(x,y-10),(x+10,y),(x,y+10),(x-10,y)],fill= line_color)\n",
    "                    \n",
    "            #check for the directory, create it if it isn't there.\n",
    "            if not os.path.exists('../../marked_images/'):\n",
    "                os.makedirs('../../marked_images/')\n",
    "            im.save('../../marked_images/marked_' + filename)\n",
    "            \n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "check_annotations('annotations/allan_visochek_4.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## if you find a faulty entry while proofreading, you can use this function to remove the entry from your json and put the image back in the queue\n",
    "def delete_entry(image, jsonfile):\n",
    "    with open(jsonfile, 'rb') as infile:\n",
    "        json_in = json.load(infile)\n",
    "        \n",
    "        new_json = [annotation for annotation in json_in if annotation['filename'][annotation['filename'].rfind('/') + 1:] != image]\n",
    "        \n",
    "    with open(jsonfile, 'wb') as outfile:\n",
    "        json.dump(new_json, outfile)\n",
    "        \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## find the specific json file (or files) with annotations for the given image\n",
    "\n",
    "def find_json(image):\n",
    "    jsons = [json_file for json_file in os.listdir('annotations') if '.json' in json_file]\n",
    "    for jfile in jsons:\n",
    "        with open('annotations/' + jfile) as infile:\n",
    "            json_in = json.load(infile)\n",
    "            for x in json_in:\n",
    "                if x['filename'][x['filename'].rfind('/') + 1:] == image:\n",
    "                    pprint(x)\n",
    "                    pprint(jfile)\n",
    "                    \n",
    "                                                     \n",
    "                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{u'annotations': [{u'class': u'neg',\n",
      "                   u'height': 483.4070981210857,\n",
      "                   u'type': u'rect',\n",
      "                   u'width': 461.7620041753653,\n",
      "                   u'x': 1875.9081419624217,\n",
      "                   u'y': 1024.5344467640919}],\n",
      " u'class': u'image',\n",
      " u'filename': u'../../../files_for_annotation/w_39.jpg'}\n",
      "'burnham11.json'\n"
     ]
    }
   ],
   "source": [
    "for x in ['w_39.jpg']:\n",
    "    find_json(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "delete_entry('w_39.jpg', 'annotations/burnham11.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## this function will create a master json file from all of the json files in the annotations folder\n",
    "\n",
    "def make_master_json():\n",
    "    master_json = []\n",
    "    images_added = []\n",
    "    # make list of all .json file in annotations folder\n",
    "    jsons = [json_doc for json_doc in os.listdir('annotations/') if '.json' in json_doc]\n",
    "    for entry in jsons:\n",
    "        \n",
    "        #import the json\n",
    "        with open('annotations/' + entry, 'rb') as infile:\n",
    "            json_in = json.load(infile)\n",
    "            for image in json_in:\n",
    "                if image['annotations'] == []:\n",
    "                    continue\n",
    "                \n",
    "                filename = image['filename'][image['filename'].rfind('/') + 1:]\n",
    "                if filename not in images_added:\n",
    "                    master_json.append(image)\n",
    "                    images_added.append(filename)\n",
    "                else:\n",
    "                    \n",
    "                    #if it has more negs than the other entry add this one and delete the other. Otherwise, skip it\n",
    "                    neg_count = 0\n",
    "                    for item in image['annotations']:\n",
    "                        if item['class'] == 'neg':\n",
    "                            neg_count += 1\n",
    "                    if neg_count == 0:\n",
    "                        continue\n",
    "                    else:\n",
    "                        #look up the other one\n",
    "                        for annotation in master_json:\n",
    "                            old_neg_count = 0\n",
    "                            old_entry = annotation['filename']\n",
    "                            for item in image['annotations']:\n",
    "                                if item['class'] == 'neg':\n",
    "                                    old_neg_count += 1\n",
    "                        if neg_count > old_neg_count:\n",
    "                            #remove the old one\n",
    "                            master_json.remove(annotation)\n",
    "                            master_json.append(image)\n",
    "                            \n",
    "                                                     \n",
    "    return master_json\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "master = make_master_json()\n",
    "with open('master_annotations.json', 'w') as outfile:\n",
    "    json.dump(master, outfile)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'bg_txt' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-44-d7e4dfd1df07>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbg_txt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'bg_txt' is not defined"
     ]
    }
   ],
   "source": [
    "bg_txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
